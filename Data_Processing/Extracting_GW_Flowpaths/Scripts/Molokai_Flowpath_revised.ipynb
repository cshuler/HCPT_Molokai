{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import arcpy\n",
    "arcpy.env.overwriteOutput = True \n",
    "from arcpy.sa import *\n",
    "from arcpy import env\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "if not os.path.exists(os.path.join(\"..\", 'workspace')): os.makedirs(os.path.join(\"..\", 'workspace'))  \n",
    "workspace = os.path.join(\"..\", 'workspace')\n",
    "\n",
    "if not os.path.exists(os.path.join(workspace,'tempspace')): os.makedirs(os.path.join(workspace,'tempspace'))  \n",
    "tempspace = os.path.join(workspace, \"tempspace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All island functions to do the GMS To Flikr cells joining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_grid_file(fromshp, toshp):    \n",
    "\n",
    "    # first make a copy\n",
    "    arcpy.CopyFeatures_management(fromshp, toshp)\n",
    "\n",
    "    # delete any cells with z>1\n",
    "    #qFlt = \"K > 1\"\n",
    "    #with arcpy.da.UpdateCursor(toshp, [\"K\"], where_clause=qFlt) as uCur:\n",
    "    #    for dRow in uCur:\n",
    "    #        uCur.deleteRow ()\n",
    "    #del uCur   # Release lock #\n",
    "\n",
    "    #arcpy.management.AddField(toshp, \"Grid_ID\", \"TEXT\")\n",
    "    #arcpy.CalculateField_management(toshp, \"Grid_ID\", \n",
    "    #                                'str(!I!) +\"_\"+ str(!J!) ', \"PYTHON3\")\n",
    "\n",
    "    # remove extranious fields\n",
    "    #fcList = [field.name for field in arcpy.ListFields(toshp)]   # list fields\n",
    "    ## This is the list of fields you want to retain\n",
    "    #fcList.remove('Grid_ID'); fcList.remove('FID'); fcList.remove('Shape') #pop off keepers\n",
    "    #for field in fcList:\n",
    "    #        arcpy.DeleteField_management(toshp, fcList)  # delete extranious fields\n",
    "\n",
    "\n",
    "def process_paths_starts(fromshp, toshp):\n",
    "\n",
    "    # first make a copy\n",
    "    arcpy.CopyFeatures_management(fromshp, toshp)\n",
    "\n",
    "    arcpy.management.AddField(toshp, \"Starts_ID\", \"TEXT\")\n",
    "    arcpy.CalculateField_management(toshp, \"Starts_ID\", \n",
    "                                    '\"starts_\" + str(!FID!) ', \"PYTHON3\")\n",
    "    # remove extranious fields\n",
    "    fcList = [field.name for field in arcpy.ListFields(toshp)]   # list fields\n",
    "    # This is the list of fields you want to retain\n",
    "    fcList.remove('Starts_ID'); fcList.remove('FID'); fcList.remove('Shape') #pop off keepers\n",
    "    for field in fcList:\n",
    "            arcpy.DeleteField_management(toshp, fcList)  # delete extranious fields\n",
    "            \n",
    "def process_paths_ends(fromshp, toshp):\n",
    "    \n",
    "    # first make a copy\n",
    "    arcpy.CopyFeatures_management(fromshp, toshp)\n",
    "\n",
    "    arcpy.management.AddField(toshp, \"Ends_ID\", \"TEXT\")\n",
    "    arcpy.CalculateField_management(toshp, \"Ends_ID\", \n",
    "                                    '\"ends_\" + str(!FID!) ', \"PYTHON3\")\n",
    "    # remove extranious fields\n",
    "    fcList = [field.name for field in arcpy.ListFields(toshp)]   # list fields\n",
    "    # This is the list of fields you want to retain\n",
    "    fcList.remove('Ends_ID'); fcList.remove('FID'); fcList.remove('Shape') #pop off keepers\n",
    "    for field in fcList:\n",
    "            arcpy.DeleteField_management(toshp, fcList)  # delete extranious fields\n",
    "            \n",
    "            \n",
    "def process_paths_lines(fromshp, toshp):\n",
    "    \n",
    "    # first make a copy\n",
    "    arcpy.CopyFeatures_management(fromshp, toshp)\n",
    "\n",
    "    arcpy.management.AddField(toshp, \"Path_ID\", \"TEXT\")\n",
    "    arcpy.CalculateField_management(toshp, \"Path_ID\", \n",
    "                                    '\"path_\" + str(!FID!) ', \"PYTHON3\")\n",
    "    # remove extranious fields\n",
    "    fcList = [field.name for field in arcpy.ListFields(toshp)]   # list fields\n",
    "    # This is the list of fields you want to retain\n",
    "    fcList.remove('Path_ID'); fcList.remove('FID'); fcList.remove('Shape') #pop off keepers\n",
    "    for field in fcList:\n",
    "            arcpy.DeleteField_management(toshp, fcList)  # delete extranious fields\n",
    "            \n",
    "            \n",
    "### Deal with the few OSDS units that smoehow didnt get a flikr cell, \n",
    "# just assign them to the geographically nearest one.\n",
    "\n",
    "def deal_with_outliers(in_features, Flikr_cells):             \n",
    "\n",
    "    arcpy.MakeFeatureLayer_management (in_features, \"ESRI_is_lame\")\n",
    "\n",
    "    #Create stupid separate layer for just the outliers\n",
    "    query = \"Flikr_ID = ''\"    # Where Flikr ID is null\n",
    "    arcpy.SelectLayerByAttribute_management('ESRI_is_lame', \"NEW_SELECTION\", query)\n",
    "    arcpy.CopyFeatures_management('ESRI_is_lame', os.path.join(tempspace, \"ESRI_is_idiotic.shp\"))\n",
    "\n",
    "    # Do the spatial join to Flikr cells\n",
    "    target_features = os.path.join(tempspace, \"ESRI_is_idiotic.shp\")\n",
    "    join_features = Flikr_cells\n",
    "    out_features =    os.path.join(tempspace, 'OutlierStarts_wFlikr_cells2.shp')\n",
    "    arcpy.SpatialJoin_analysis(target_features, join_features, out_features, match_option=\"CLOSEST\")\n",
    "\n",
    "    ## Clean up the fields in the outlier shp to only include needed ones\n",
    "    shp = os.path.join(tempspace, 'OutlierStarts_wFlikr_cells2.shp')\n",
    "    fcList = [field.name for field in arcpy.ListFields(shp)]   # list fields\n",
    "    fcList.remove('Flikr_ID_1'); fcList.remove('Starts_ID'); fcList.remove('FID'); fcList.remove('Shape') #pop off keepers  (Flokr_ID_1 is autogenerated when the 2nd merge is done)\n",
    "    for field in fcList:\n",
    "            arcpy.DeleteField_management(shp, fcList)  # delete extranious fields\n",
    "\n",
    "    # read the paths data from shapefile into a pandas dataframe\n",
    "    paths_path = os.path.join(tempspace, 'OutlierStarts_wFlikr_cells2.shp')\n",
    "    columns_nams = [field.name for field in arcpy.ListFields(paths_path)]\n",
    "    columns_nams.pop(1)  # remove stupid shape col\n",
    "    temparr = arcpy.da.FeatureClassToNumPyArray(paths_path, columns_nams)\n",
    "    Outlier_starts_DF =  pd.DataFrame(temparr)\n",
    "\n",
    "    # read the paths data from shapefile into a pandas dataframe\n",
    "    paths_path = os.path.join(tempspace, 'starts_wGridCells_wPaths_wEnds_wFlikr_cells.shp')\n",
    "    columns_nams = [field.name for field in arcpy.ListFields(paths_path)]\n",
    "    columns_nams.pop(1)  # remove stupid shape col\n",
    "    temparr = arcpy.da.FeatureClassToNumPyArray(paths_path, columns_nams)\n",
    "    OSDS_flkrEndTmp_DF =  pd.DataFrame(temparr)\n",
    "\n",
    "    # Do the merge addin on the outliers to the goodframe \n",
    "    OSDS_flkrEndTmp_DF_merge = OSDS_flkrEndTmp_DF.merge(Outlier_starts_DF, on='Starts_ID', how='left')\n",
    "\n",
    "    # Merge the flikr IDs with the replacements for the nanns\n",
    "    OSDS_flkrEndTmp_DF_merge['Flikr_IDmerged2'] = np.where(OSDS_flkrEndTmp_DF_merge['Flikr_ID'] == \" \", OSDS_flkrEndTmp_DF_merge['Flikr_ID_1'], OSDS_flkrEndTmp_DF_merge['Flikr_ID'])\n",
    "    del OSDS_flkrEndTmp_DF_merge['Flikr_ID_1']; del OSDS_flkrEndTmp_DF_merge['Flikr_ID']\n",
    "\n",
    "    # rename columns \n",
    "    OSDS_flkrEndTmp_DF_merge = OSDS_flkrEndTmp_DF_merge.rename(columns={ 'Flikr_IDmerged2':'Flikr_ID'})   # 'Cess_ID':\"Uid\",? rename the cespool ID for some reason\n",
    "    #Cut out extranious columns\n",
    "    carelist = [\"Grid_ID\", \"Flikr_X\", \"Flikr_Y\", \"Flikr_ID\"]\n",
    "    OSDS_flkrEndTmp_DF_merge = OSDS_flkrEndTmp_DF_merge[carelist]\n",
    "\n",
    "    ### Add the island designator and be sure to chage this for other islands\n",
    "    OSDS_flkrEndTmp_DF_merge[\"Island\"] = island_name\n",
    "    \n",
    "    Outframe = OSDS_flkrEndTmp_DF_merge.copy()\n",
    "    \n",
    "    return Outframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punch in paths to island specific files here: For Molokai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMS_grid_file =    os.path.join(\"..\", \"GMS_Export\", \"Mokai_grid_cleaned_OSDS_Intersect.shp\")\n",
    "Pathlines_starts = os.path.join(\"..\", \"GMS_Export\", \"Molokai_pathlines_starts.shp\")\n",
    "Pathlines_ends =   os.path.join(\"..\", \"GMS_Export\", \"Molokai_pathlines_ends.shp\")\n",
    "Pathlines_paths =  os.path.join(\"..\", \"GMS_Export\", \"Molokai_pathlines.shp\")\n",
    "Flikr_cells =      os.path.join(\"..\", \"Fliker_cell_data\", \"Flikr_MoKai_250_cells_wMidpoints.shp\")\n",
    "island_name        = \"Molokai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up grid Is already done....  Function is commented out above. \n",
    "fromshp = GMS_grid_file\n",
    "toshp   = os.path.join(workspace, \"grid_cleaned.shp\")\n",
    "clean_grid_file(fromshp, toshp)\n",
    "\n",
    "# Clean up starts\n",
    "fromshp = Pathlines_starts\n",
    "toshp   = os.path.join(workspace, \"pathline_starts_cleaned.shp\")\n",
    "process_paths_starts(fromshp, toshp)\n",
    "\n",
    "# Clean up ends \n",
    "fromshp = Pathlines_ends\n",
    "toshp   = os.path.join(workspace, \"pathline_ends_cleaned.shp\")\n",
    "process_paths_ends(fromshp, toshp)\n",
    "\n",
    "# Clean up paths \n",
    "fromshp = Pathlines_paths\n",
    "toshp   = os.path.join(workspace, \"pathlines_clean.shp\")\n",
    "process_paths_lines(fromshp, toshp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do all the joins ###\n",
    "\n",
    "# Every start point has a corresponding grid cell\n",
    "target_features = os.path.join(workspace, \"pathline_starts_cleaned.shp\")\n",
    "join_features =   os.path.join(workspace, \"grid_cleaned.shp\")\n",
    "out_features =    os.path.join(tempspace, 'starts_wGridCells.shp')\n",
    "\n",
    "arcpy.SpatialJoin_analysis(target_features, join_features, out_features, match_option=\"INTERSECT\")\n",
    "\n",
    "\n",
    "# Every end point needs a ending flikr cell \n",
    "target_features = os.path.join(workspace, \"pathline_ends_cleaned.shp\")\n",
    "join_features = Flikr_cells    \n",
    "out_features =    os.path.join(tempspace, 'Ends_wFlikr_cells.shp')\n",
    "\n",
    "arcpy.SpatialJoin_analysis(target_features, join_features, out_features, match_option=\"CLOSEST\")\n",
    "\n",
    "\n",
    "# Every path has a corresponding end point Connect the paths to the path ends\n",
    "target_features =    os.path.join(workspace, \"pathlines_clean.shp\")\n",
    "join_features =     os.path.join(tempspace, 'Ends_wFlikr_cells.shp')  \n",
    "out_features =      os.path.join(tempspace, 'Paths_wEnds_wFlikr_cells.shp')\n",
    "# for some reason the end points are not perfectly matched, they are centimeters off\n",
    "arcpy.SpatialJoin_analysis(target_features, join_features, out_features, match_option=\"INTERSECT\", search_radius=1) \n",
    "\n",
    "\n",
    "# Connect the starts to the path/ends\n",
    "target_features = os.path.join(tempspace, 'starts_wGridCells.shp')\n",
    "join_features =   os.path.join(tempspace, 'Paths_wEnds_wFlikr_cells.shp')\n",
    "out_features =    os.path.join(tempspace, 'starts_wGridCells_wPaths_wEnds_wFlikr_cells.shp')\n",
    "\n",
    "arcpy.SpatialJoin_analysis(target_features, join_features, out_features, match_option=\"INTERSECT\")\n",
    "\n",
    "\n",
    "# Deal with the few OSDS units that smoehow didnt get a flikr cell\n",
    "in_features =    os.path.join(tempspace, 'starts_wGridCells_wPaths_wEnds_wFlikr_cells.shp')\n",
    "Outframe = deal_with_outliers(in_features, Flikr_cells)\n",
    "\n",
    "Outframe['Flikr_ID_statewide'] = Outframe['Flikr_ID']+\"_\"+Outframe['Island']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Create the final Grid-polygon shapefile with the Fliker_IDs as a field: FOR: Molokai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result '..\\\\Outputs\\\\Molokai_grid_w_Flikr_IDs.shp'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy pristine GriD Polygon File to something that can be joined on\n",
    "in_polygon_GRID = os.path.join(workspace, \"grid_cleaned.shp\")\n",
    "arcpy.CopyFeatures_management(in_polygon_GRID, os.path.join(\"..\", \"Outputs\", '{}_grid_w_Flikr_IDs.shp'.format(island_name)))  \n",
    "\n",
    "# Convert the pandas dataframe to an idiotic arc table view format (lame!)\n",
    "Outframe.to_csv(os.path.join(tempspace, 'temp.csv'))\n",
    "arcpy.TableToTable_conversion(os.path.join(tempspace, 'temp.csv'), os.path.join(tempspace), \"esrisucks\")\n",
    "arcpy.management.MakeTableView(os.path.join(tempspace, \"esrisucks.dbf\"), \"esriislame\")\n",
    "\n",
    "# Do the table joining\n",
    "in_polygons = os.path.join(\"..\", \"Outputs\", '{}_grid_w_Flikr_IDs.shp'.format(island_name))\n",
    "joinfield = \"Grid_ID\"\n",
    "arcpy.JoinField_management(in_polygons, joinfield, \"esriislame\", joinfield) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
