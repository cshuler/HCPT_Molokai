{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import arcpy\n",
    "arcpy.env.overwriteOutput = True \n",
    "from arcpy.sa import *\n",
    "from arcpy import env\n",
    "\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "\n",
    "# relative paths\n",
    "homedir = os.getcwd()\n",
    "if not os.path.exists(os.path.join(homedir,'tempspace')): os.makedirs(os.path.join(homedir,'tempspace'))  \n",
    "tempspace = os.path.join(homedir, \"tempspace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OSDS V5\n",
    "#osds_v5 = pd.read_csv(os.path.join(\".\", 'Workspace', \"OSDS_v5DwellDat_moKai_CP.shp\"), index_col=0)  # If its in a csv already\n",
    "\n",
    "osds_path = os.path.join(\".\", 'Workspace', \"OSDS_v5DwellDat_moKai_CP.shp\")\n",
    "columns_nams = [field.name for field in arcpy.ListFields(osds_path)]     # List of all col names\n",
    "columns_nams.pop(1)  # remove stupid shape col                           # THe \"Shape\" col will make numpy array to pandas puke\n",
    "temparr = arcpy.da.FeatureClassToNumPyArray(osds_path, columns_nams)     # convert to numpy recarray\n",
    "osds_v5 = pd.DataFrame(temparr)                                       # Convert to pandas bliss\n",
    "\n",
    "# Specify clearly the column which holds the number of cesspools per parcel\n",
    "osds_v5['OSDS_QTY_calc'] = osds_v5[\"CLASS_IV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dots for Parcels with 9 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1 parcels to explode\n"
     ]
    }
   ],
   "source": [
    "# The number of points to work with \n",
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 9]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# Create empty container to house new dataframes\n",
    "frame_9 = pd.DataFrame(columns = osds_v5_exp.columns)\n",
    "\n",
    "# Loop through and create a new point for every multi point point\n",
    "for row in osds_v5_exp.iterrows():\n",
    "    base = pd.DataFrame(row[1]).transpose()\n",
    "    \n",
    "    # Add East unit\n",
    "    Unit_2 = base.copy()\n",
    "    Unit_2['X'] = Unit_2['X'] + 0.0001\n",
    "    \n",
    "    # Add West unit\n",
    "    Unit_3 = base.copy()\n",
    "    Unit_3['X'] = Unit_3['X'] - 0.0001\n",
    "    \n",
    "    # Add North unit\n",
    "    Unit_4 = base.copy()\n",
    "    Unit_4['Y'] = Unit_4['Y'] + 0.0001\n",
    "    \n",
    "    # Add South unit\n",
    "    Unit_5 = base.copy()\n",
    "    Unit_5['Y'] = Unit_5['Y'] - 0.0001\n",
    "    \n",
    "    # Add NorthEast unit\n",
    "    Unit_6 = base.copy()\n",
    "    Unit_6['Y'] = Unit_6['Y'] + 0.0001\n",
    "    Unit_6['X'] = Unit_6['X'] + 0.0001\n",
    "    \n",
    "    # Add SouthEast unit\n",
    "    Unit_7 = base.copy()\n",
    "    Unit_7['Y'] = Unit_7['Y'] - 0.0001\n",
    "    Unit_7['X'] = Unit_7['X'] + 0.0001\n",
    "    \n",
    "    # Add NorthWest unit\n",
    "    Unit_8 = base.copy()\n",
    "    Unit_8['Y'] = Unit_8['Y'] + 0.0001\n",
    "    Unit_8['X'] = Unit_8['X'] - 0.0001\n",
    "    \n",
    "    # Add SouthWest unit\n",
    "    Unit_9 = base.copy()\n",
    "    Unit_9['Y'] = Unit_9['Y'] - 0.0001\n",
    "    Unit_9['X'] = Unit_9['X'] - 0.0001\n",
    "    \n",
    "    New_units_same_TMK = pd.concat([Unit_2, Unit_3, Unit_4, \n",
    "                                    Unit_5, Unit_6, Unit_7, Unit_8, Unit_9], ignore_index=True, sort=False)\n",
    "    \n",
    "    frame_9 = frame_9.append(New_units_same_TMK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 0 parcels to explode\n",
      "there are 0 parcels to explode\n",
      "there are 0 parcels to explode\n",
      "there are 0 parcels to explode\n",
      "there are 1 parcels to explode\n"
     ]
    }
   ],
   "source": [
    "# Check if we need to explode other quantities  Apparently not for 8-5 \n",
    "\n",
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 8]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# The number of points to work with \n",
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 7]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# The number of points to work with \n",
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 6]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# The number of points to work with \n",
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 5]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# The number of points to work with \n",
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] ==4]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dots for Parcels with 4 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 1 parcels to explode\n"
     ]
    }
   ],
   "source": [
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 4]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# Create empty container to house new dataframes\n",
    "frame_4 = pd.DataFrame(columns = osds_v5_exp.columns)\n",
    "\n",
    "# Loop through and create a new point for every multi point point\n",
    "for row in osds_v5_exp.iterrows():\n",
    "    base = pd.DataFrame(row[1]).transpose()\n",
    "    \n",
    "    # Add East unit\n",
    "    Unit_2 = base.copy()\n",
    "    Unit_2['X'] = Unit_2['X'] + 0.0001\n",
    "    \n",
    "    # Add West unit\n",
    "    Unit_3 = base.copy()\n",
    "    Unit_3['X'] = Unit_3['X'] - 0.0001\n",
    "    \n",
    "    # Add North unit\n",
    "    Unit_4 = base.copy()\n",
    "    Unit_4['Y'] = Unit_4['Y'] + 0.0001\n",
    "      \n",
    "    New_units_same_TMK = pd.concat([Unit_2, Unit_3, Unit_4], ignore_index=True, sort=False)\n",
    "    \n",
    "    frame_4 = frame_4.append(New_units_same_TMK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dots for Parcels with 3 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 6 parcels to explode\n"
     ]
    }
   ],
   "source": [
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 3]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# Create empty container to house new dataframes\n",
    "frame_3 = pd.DataFrame(columns = osds_v5_exp.columns)\n",
    "\n",
    "# Loop through and create a new point for every multi point point\n",
    "for row in osds_v5_exp.iterrows():\n",
    "    base = pd.DataFrame(row[1]).transpose()\n",
    "    \n",
    "    # Add East unit\n",
    "    Unit_2 = base.copy()\n",
    "    Unit_2['X'] = Unit_2['X'] + 0.0001\n",
    "    \n",
    "    # Add West unit\n",
    "    Unit_3 = base.copy()\n",
    "    Unit_3['X'] = Unit_3['X'] - 0.0001\n",
    "    \n",
    "   \n",
    "    New_units_same_TMK = pd.concat([Unit_2, Unit_3], ignore_index=True, sort=False)\n",
    "    \n",
    "    frame_3 = frame_3.append(New_units_same_TMK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dots for Parcels with 2 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 90 parcels to explode\n"
     ]
    }
   ],
   "source": [
    "osds_v5_exp = osds_v5[osds_v5['OSDS_QTY_calc'] == 2]\n",
    "print(\"there are {} parcels to explode\".format(len(osds_v5_exp)))\n",
    "\n",
    "# Create empty container to house new dataframes\n",
    "frame_2 = pd.DataFrame(columns = osds_v5_exp.columns)\n",
    "\n",
    "# Loop through and create a new point for every multi point point\n",
    "for row in osds_v5_exp.iterrows():\n",
    "    base = pd.DataFrame(row[1]).transpose()\n",
    "    \n",
    "    # Add East unit\n",
    "    Unit_2 = base.copy()\n",
    "    Unit_2['X'] = Unit_2['X'] + 0.0001\n",
    "    \n",
    "   \n",
    "    New_units_same_TMK = pd.concat([Unit_2], ignore_index=True, sort=False)\n",
    "    \n",
    "    frame_2 = frame_2.append(New_units_same_TMK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now merge all  <9 exploded units together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exploded_units_LT9 = pd.concat([frame_2, frame_3, frame_4,  frame_9]) # frame_5, frame_6,  frame_7, frame_8,\n",
    "\n",
    "Exploded_units_LT9.to_csv(os.path.join(tempspace, \"Just_multi_unit_parcels_LT9_v2.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My 's (>10 units on a parcel) exploded units\n",
    "Where I  manually exploded out the units by looking at the sat imagry and manually editing the file to add points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\".\", 'Workspace/Manually_Exploded' )    ####### Change the path Obvi\n",
    "dic_space = {}\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".shp\"):      \n",
    "        datapath = os.path.join(path, file)\n",
    "        name_ID = file[:-4]   # ; print(name_ID)\n",
    "        \n",
    "        # Add the XY fields\n",
    "        data_with_XY = arcpy.Copy_management(datapath, os.path.join(tempspace, \"tempshape.shp\"))\n",
    "        # Execute AddXY\n",
    "        arcpy.AddXY_management(data_with_XY)\n",
    "        \n",
    "        # Convert to beautiful pandas dataframe\n",
    "        columns_nams = [field.name for field in arcpy.ListFields(data_with_XY)]     # List of all col names\n",
    "        columns_nams.pop(1)  # remove stupid shape col                           # THe \"Shape\" col will make numpy array to pandas puke\n",
    "        temparr = arcpy.da.FeatureClassToNumPyArray(data_with_XY, columns_nams)     # convert to numpy recarray\n",
    "        data = pd.DataFrame(temparr)  \n",
    "        \n",
    "        # Compile dataframes for concating later\n",
    "        dic_space[name_ID]  = data\n",
    "        \n",
    "# Merge all exploded datas into one dataframe \n",
    "Kaitlin_exploded_units = pd.concat(dic_space.values(), ignore_index=True)\n",
    "# Correct the geometry column headings \n",
    "Kaitlin_exploded_units['X'] = Kaitlin_exploded_units['POINT_X']\n",
    "Kaitlin_exploded_units['Y'] = Kaitlin_exploded_units['POINT_Y']\n",
    "del Kaitlin_exploded_units['POINT_X']; del Kaitlin_exploded_units['POINT_Y']\n",
    "\n",
    "# Deal with some Column header issues caused by ESRI's lack of goodattheirjobness\n",
    "if 'OSDS_QTY_c' in Kaitlin_exploded_units.columns: \n",
    "    Kaitlin_exploded_units = Kaitlin_exploded_units.rename(columns={'OSDS_QTY_c': 'OSDS_QTY_calc'})\n",
    "\n",
    "wantcols = ['FID', 'TMK', 'OSDS_QTY', 'CLASS_I', 'CLASS_II', 'CLASS_III',\n",
    "       'CLASS_IV', 'EFFLUENT', 'N_FLUX', 'P_FLUX', 'SOURCE', 'NO_STRUCT',\n",
    "       'TTL_BDRMS', 'NO_BATH', 'X', 'Y', 'Island', 'OSDS_TYP', 'B_ROOMS',\n",
    "       'BATHS', 'Class_type', 'commercial', 'type', 'OSDS_QTY_calc']\n",
    "\n",
    "Kaitlin_exploded_units = Kaitlin_exploded_units[wantcols]\n",
    "\n",
    "Kaitlin_exploded_units.to_csv(os.path.join(tempspace, \"KaitlinMy_exploded_MoKai_NOBI.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Kaitlin and  <9 exploded units together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ALL_exploded_units = pd.concat([Exploded_units_LT9, Kaitlin_exploded_units])\n",
    "\n",
    "ALL_exploded_units.to_csv(os.path.join(tempspace, \"All_Exploded_multi_unit_parcels.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OSDSv6 where the dewll dat verrified units are merged with the exploded units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Merge the OSDS v5 and the exploded ones\n",
    "OSDS_v6_Exploded = pd.concat([osds_v5, ALL_exploded_units])\n",
    "OSDS_v6_Exploded.to_csv(os.path.join(tempspace, \"OSDSv6_Exploded_ALL.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Cesspool ONLY Dataset\n",
    "Asssume_cesspools = OSDS_v6_Exploded[(OSDS_v6_Exploded['CLASS_I'] ==0) & (OSDS_v6_Exploded['CLASS_II'] ==0) \n",
    "                 & (OSDS_v6_Exploded['CLASS_III'] ==0)& (OSDS_v6_Exploded['CLASS_IV'] ==0)]   # if there isnt a number for any class\n",
    "\n",
    "Labeled_cesspools = OSDS_v6_Exploded[OSDS_v6_Exploded['CLASS_IV'] > 0]   \n",
    "\n",
    "CESSPOOLS_v6_Exploded = pd.concat([Asssume_cesspools, Labeled_cesspools])\n",
    "CESSPOOLS_v6_Exploded.to_csv(os.path.join(\".\", \"Outs\", \"CESSPOOLSv6_Exploded.csv\"))\n",
    "\n",
    "\n",
    "# Create the class 1, 2, 3 only datasets\n",
    "SEPTICS_v6_Exploded = OSDS_v6_Exploded[(OSDS_v6_Exploded['CLASS_I'] > 0) | (OSDS_v6_Exploded['CLASS_II'] >0) \n",
    "                 | (OSDS_v6_Exploded['CLASS_III'] > 0)]\n",
    "\n",
    "SEPTICS_v6_Exploded.to_csv(os.path.join(\".\", \"Outs\", \"SEPTICS_v6_Exploded.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result '.\\\\Outs'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send to a shapefile too \n",
    "spatialRef = arcpy.SpatialReference(4326)\n",
    "csvFilePath =  os.path.join(\".\", \"Outs\", \"CESSPOOLSv6_Exploded.csv\")   \n",
    "shpFilePath = os.path.join(os.path.join(\".\", \"Outs\"))\n",
    "arcpy.MakeXYEventLayer_management(csvFilePath, 'X', 'Y', 'CESSPOOLSv6_Exploded', spatial_reference=spatialRef)\n",
    "arcpy.FeatureClassToShapefile_conversion('CESSPOOLSv6_Exploded', shpFilePath)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
